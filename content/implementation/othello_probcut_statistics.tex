\begin{lstlisting}[language=Python]
%%HTML
<style>
.container { width:100% }
</style>
\end{lstlisting}

\begin{lstlisting}[language=Python]
%run othello_game.ipynb
%run othello_ai.ipynb
\end{lstlisting}

\hypertarget{ermitteln-der-standardabweichung}{%
\paragraph{Ermitteln der
Standardabweichung}\label{ermitteln-der-standardabweichung}}

Im Folgenden werden zunächst einige Datenpunkte gesammelt, indem in
verschiedenen Spielzuständen jeweils eine tiefe und eine flache Suche
durchgeführt wird. Die Spielzustände werden durch zufälliges Ziehen
erreicht. Die Daten werden in einer CSV-Datei gespeichert.

\begin{lstlisting}[language=Python]
import csv
import os


def sample_probcut_values(num_games, shallow_depth, deep_depth):
    fname = f'probcut_dataset_{PROBCUT_SHALLOW_DEPTH}_{PROBCUT_DEEP_DEPTH}.csv'
    file_exists = os.path.isfile(fname)
    if file_exists:
        print('using existing dataset')
    else:
        with open(fname, 'w', newline='') as file:
            writer = csv.writer(file, delimiter=',')
            writer.writerow(('moves', 'shallow', 'deep'))
            for i in range(num_games):
                state = GameState()
                while not state.game_over:
                    state = ai_make_move(random_ai, state, 0, None)
                    shallow_value = alphabeta(
                        state, PROBCUT_SHALLOW_DEPTH,
                        combined_heuristic, -math.inf, math.inf
                    )
                    deep_value = alphabeta(
                        state, PROBCUT_DEEP_DEPTH,
                        combined_heuristic, -math.inf, math.inf
                    )
                    print(f'shallow: {shallow_value}, deep: {deep_value}')
                    writer.writerow(
                        (state.num_pieces, shallow_value, deep_value))
            file.close()
\end{lstlisting}

\begin{lstlisting}[language=Python]
sample_probcut_values(100, PROBCUT_SHALLOW_DEPTH, PROBCUT_DEEP_DEPTH)
\end{lstlisting}

Laden der Daten aus der CSV-Datei mithilfe von Pandas

\begin{lstlisting}[language=Python]
import pandas
filename = f'probcut_dataset_{PROBCUT_SHALLOW_DEPTH}_{PROBCUT_DEEP_DEPTH}.csv'
df = pandas.read_csv(filename)
shallow = np.array(df['shallow'])
deep = np.array(df['deep'])
moves = np.array(df['moves'])
\end{lstlisting}

Daten Visualisieren

\begin{lstlisting}[language=Python]
import matplotlib.pyplot as plt
import sklearn.linear_model as lm
import seaborn as sns
model = lm.LinearRegression()
model.fit(shallow.reshape(len(shallow), 1), deep)
plt.figure(figsize=(15, 10))
sns.set(style='whitegrid')
plt.scatter(shallow, deep)
plt.axvline(x=0.0, c='k')
plt.axhline(y=0.0, c='k')
plt.plot(shallow, shallow * model.coef_ + model.intercept_)
plt.xlabel('shallow search')
plt.ylabel('deep search')
plt.title('Probcut Values')
plt.show()
\end{lstlisting}

Folgender Code berechnet die Standardabweichung pro Anzahl Steine auf
dem Spielfeld. Dazu werden zunächst für jede Anzahl an Steinen aus den
Daten die passenden Werte extrahiert. Für diese Teilmengen wird jeweils
die Varianz mit \(numpy\) berechnet. Die Standardabweichung ist die
positive Wurzel aus der Varianz. Die Anzahl an Steinen und die
Standardabweichung werden an entsprechende Felder angehängt.

\begin{lstlisting}[language=Python]
import numpy as np
import sklearn.metrics as skl
import sklearn.linear_model as lm
import matplotlib.pyplot as plt
import seaborn as sns
import math

x = []
y = []

for i in range(5, 45):
    shallow_c = shallow[moves == i]
    deep_c = deep[moves == i]
    variance = np.var(np.stack([shallow_c, deep_c], axis=1))
    explained_variance = skl.explained_variance_score(shallow_c, deep_c)
    x.append(i)
    y.append(math.sqrt(variance))
    #print(f'{i}: Var={round(variance, 5)}, explained: {round(explained_variance, 3)}')
\end{lstlisting}

Folgender Code berechnet die Regressionsgerade der Standardabweichung in
Abhängigkeit von der Anzahl der Steine auf dem Spielfeld mit \(sklearn\)
und stellt diese grafisch dar.

\begin{lstlisting}[language=Python]
model = lm.LinearRegression()
model.fit(np.array(x).reshape(-1, 1), np.array(y))

plt.figure(figsize=(15, 10))
sns.set(style='whitegrid')
plt.scatter(x, y)
plt.axvline(x=0.0, c='k')
plt.axhline(y=0.0, c='k')
plt.plot(x, x * model.coef_ + model.intercept_)
plt.xlabel('number of disks on the board')
plt.ylabel('standard deviation')
plt.title('Standard Deviation')
plt.show()
\end{lstlisting}

Ausgeben der Funktion der Regressionsgerade, welche die
Standardabweichung in Abhängigkeit von der Anzahl an Spielsteinen auf
dem Spielfeld berechnet

\begin{lstlisting}[language=Python]
print('x *', model.coef_[0], '+', model.intercept_)
\end{lstlisting}

Varianz, erklärte Varianz und Standardabweichung berechnen

\begin{lstlisting}[language=Python]
import numpy as np
import sklearn.metrics as skl
variance = np.var(np.stack([shallow, deep], axis=1))
print(f'variance: {variance}')
explained_variance = skl.explained_variance_score(shallow, deep)
print(f'standard distribution: {np.sqrt(variance)}')
print(f'explained variance: {explained_variance}')
\end{lstlisting}

\begin{lstlisting}[language=Python]
\end{lstlisting}
